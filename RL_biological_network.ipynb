{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BIOLOGICAL NETWORK"
      ],
      "metadata": {
        "id": "Vo-WDv2zAdtn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoaOvaACywRd"
      },
      "outputs": [],
      "source": [
        "# Author: Dani Gunawan\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connectivity matrix\n",
        "conn_matrix = np.array([[ 0, 0, -1,  0],\n",
        "                        [ 1, 0, -1, -1],\n",
        "                        [ 0, 1,  0,  0],\n",
        "                        [-1, 1,  1,  0]])\n",
        "\n",
        "# state space s1-s16\n",
        "s = np.array([[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 1], \n",
        "              [0, 1, 0, 0], [0, 1, 0, 1], [0, 1, 1, 0], [0, 1, 1, 1],\n",
        "              [1, 0, 0, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 1],\n",
        "              [1, 1, 0, 0], [1, 1, 0, 1], [1, 1, 1, 0], [1, 1, 1, 1]])\n",
        "\n",
        "# action\n",
        "a = np.array([[0, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1]])\n",
        "\n",
        "max = 16"
      ],
      "metadata": {
        "id": "N_vTqV6KhytC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transition_prob(s_row, s_col, c_mat, a, p):\n",
        "  # calculate L-1 norm\n",
        "  cs = np.dot(c_mat, np.transpose(s_row))\n",
        "  cs_bar = []\n",
        "  for n in cs:\n",
        "    if n <= 0:\n",
        "      cs_bar.append(0)\n",
        "    else:\n",
        "      cs_bar.append(1)\n",
        "\n",
        "  l1 = np.sum(np.abs(s_col - np.logical_xor(cs_bar, a)))\n",
        "\n",
        "  prob = np.power(p, l1) * np.power((1-p), (4-l1))\n",
        "\n",
        "  return prob\n"
      ],
      "metadata": {
        "id": "GnIykpAzkk6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transition_matrix(p, states, actions, c_mat):\n",
        "  \n",
        "  t_matrix = []\n",
        "\n",
        "  for act in actions:\n",
        "    m = np.zeros((max, max))\n",
        "    for i in range(0,max):\n",
        "      for j in range(0, max):\n",
        "        m[i][j] = get_transition_prob(states[i], states[j], c_mat, act, p)\n",
        "    #print(np.sum(m, axis=1)) # the sum of transition matrix row should be 1\n",
        "    t_matrix.append(m)\n",
        "\n",
        "  return t_matrix"
      ],
      "metadata": {
        "id": "37VO6lgWpA_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_reward_matrix(states, actions):\n",
        "\n",
        "  r_matrix = []\n",
        "\n",
        "  for act in actions:\n",
        "    m = np.zeros((max, max))\n",
        "    for i in range(0,max):\n",
        "      for j in range(0, max):\n",
        "        m[i][j] = (5*states[j][0])+(5*states[j][1])+(5*states[j][2])+(5*states[j][3])-np.sum(act)\n",
        "    r_matrix.append(m)\n",
        "\n",
        "  return r_matrix"
      ],
      "metadata": {
        "id": "eAdfqGb4OaKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_reward_action(t_mat, r_mat, actions):\n",
        "\n",
        "  rs_a = []\n",
        "\n",
        "  vec_nx1 = np.full(max, 1) \n",
        "\n",
        "  for i in range(0, len(actions)):\n",
        "    rs_a.append(np.dot(np.multiply(t_mat[i], r_mat[i]), np.transpose(vec_nx1)))\n",
        "\n",
        "  return rs_a"
      ],
      "metadata": {
        "id": "CbT63RhPbRiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def value_iteration_matrix(actions, t_mat, rsa, g, t):\n",
        "  v = []\n",
        "  v.append(np.zeros(max))\n",
        "  v_star = 0\n",
        "  n = 0  \n",
        "  \n",
        "  while (True):\n",
        "    #print(\"Iteration: \" + str(n))\n",
        "    #print(v[n])\n",
        "    tmp_v = []\n",
        "    for i in range(0, len(actions)):\n",
        "      tmp_v.append(rsa[i]+(g*np.dot(t_mat[i], v[n])))\n",
        "    \n",
        "    v.append(np.amax(tmp_v, axis=0))\n",
        "  \n",
        "    dv_max = np.max(np.absolute(np.subtract(v[n+1], v[n])))\n",
        "    #print(dv_max)\n",
        "    \n",
        "    if dv_max < t:\n",
        "      v_star = v[n+1]\n",
        "      break\n",
        "    else:\n",
        "      n += 1\n",
        "  \n",
        "  # calculate optimal policy\n",
        "  pi = []\n",
        "  for i in range(0, len(actions)):\n",
        "    pi.append(rsa[i]+(g*np.dot(t_mat[i], v_star)))\n",
        "  \n",
        "  p_star = np.argmax(pi, axis=0)\n",
        "\n",
        "  return np.array(p_star), np.array(v_star)"
      ],
      "metadata": {
        "id": "fRJQ8HUc9ZcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_evaluation(pi, t_m, no_control=False):\n",
        "\n",
        "  # performance evaluation\n",
        "  avg = []\n",
        "  \n",
        "  print('+----+-----------+')\n",
        "  print('| #i |   State   |')\n",
        "  print('+----+-----------+')\n",
        "\n",
        "  for e in range(0, 100):\n",
        "    idx = np.random.randint(0, max) # index state, initially set random\n",
        "\n",
        "    d = [] # trajectory\n",
        "    #idx\n",
        "    for i in range(0, 200):\n",
        "\n",
        "      # this index is obtained from optimal policy, \n",
        "      # to determine transition matrix associated with the optimal policy (action)\n",
        "      if no_control==True:\n",
        "        act_idx = 0 # set to policy a1\n",
        "      else:\n",
        "        act_idx = pi[idx] \n",
        "\n",
        "      ## find next state\n",
        "      # get all possibilities in transition matrix, row state idx\n",
        "      # then, apply cumulative sum \n",
        "      prob = np.cumsum(t_m[act_idx][idx]) \n",
        "\n",
        "      # generate random values uniformly\n",
        "      r = np.random.uniform(0, 1)\n",
        "      #print(r)\n",
        "      tmp_idx = 0\n",
        "      for pb in prob:\n",
        "        if r<=pb:\n",
        "          #if e == 0 and i < 30:\n",
        "          #  print('r = ' + str(np.round(r, 10)) + ' idx =  ' + str(tmp_idx) + ' ', end='')\n",
        "          break #stop\n",
        "        else:\n",
        "          tmp_idx += 1\n",
        "\n",
        "      idx = tmp_idx # new state index\n",
        "\n",
        "      # sum |sk|\n",
        "      # print(np.sum(s[idx]))\n",
        "      # print first n values\n",
        "      if e == 0 and i < 15:\n",
        "        print('| ' + str(i+1).rjust(2, '0') + ' | ', end='')\n",
        "        print(s[idx], end='')\n",
        "        print(' |')\n",
        "      d.append(np.sum(s[idx]))\n",
        "      \n",
        "      #print(d)\n",
        "      #print(np.shape(d))\n",
        "      #print(\"Avg\")\n",
        "      #print(np.average(d))\n",
        "\n",
        "    #print(np.shape(d))\n",
        "    avg.append(np.average(d))\n",
        "    #print(np.shape(avg))\n",
        "\n",
        "  print('+----+-----------+')\n",
        "\n",
        "  return np.average(avg)"
      ],
      "metadata": {
        "id": "az8lKg_NZWfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PROBLEM 2 - a (MATRIX FORM - VALUE ITERATION)\n",
        "\n",
        "𝑝=0.05, 𝜃=0.01, 𝛾=0.95, all-zero initial state values"
      ],
      "metadata": {
        "id": "4e37hc1IAhbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.05\n",
        "g = 0.95\n",
        "t = 0.01\n",
        "\n",
        "t_m = generate_transition_matrix(p, s, a, conn_matrix)\n",
        "\n",
        "r_m = generate_reward_matrix(s, a)\n",
        "\n",
        "r_a = generate_reward_action(t_m, r_m, a)\n",
        "\n",
        "pi, vi = value_iteration_matrix(a, t_m, r_a, g, t)\n",
        "\n",
        "print(\"Optimal Policy:\")\n",
        "print(pi)\n",
        "#print(\"V star:\")\n",
        "#print(vi)\n",
        "\n",
        "av = performance_evaluation(pi, t_m)\n",
        "\n",
        "print(\"\\nNo control: \")\n",
        "\n",
        "av_noc = performance_evaluation(pi, t_m, True) # no control\n",
        "\n",
        "print(\"AvgA under optimal control policy: {}\".format(av))\n",
        "\n",
        "print(\"AvgA under no control policy: {}\".format(av_noc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vpa9ov3AONp",
        "outputId": "6d31749e-08d4-431a-d059-b31cafe963b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy:\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "+----+-----------+\n",
            "| #i |   State   |\n",
            "+----+-----------+\n",
            "| 01 | [1 0 1 1] |\n",
            "| 02 | [0 0 0 0] |\n",
            "| 03 | [1 0 0 0] |\n",
            "| 04 | [1 1 0 0] |\n",
            "| 05 | [1 1 1 0] |\n",
            "| 06 | [1 0 1 1] |\n",
            "| 07 | [1 0 0 0] |\n",
            "| 08 | [1 1 0 0] |\n",
            "| 09 | [1 0 1 0] |\n",
            "| 10 | [1 0 0 0] |\n",
            "| 11 | [1 1 0 0] |\n",
            "| 12 | [1 1 1 0] |\n",
            "| 13 | [1 0 1 1] |\n",
            "| 14 | [1 0 0 0] |\n",
            "| 15 | [0 1 0 0] |\n",
            "+----+-----------+\n",
            "\n",
            "No control: \n",
            "+----+-----------+\n",
            "| #i |   State   |\n",
            "+----+-----------+\n",
            "| 01 | [0 0 0 0] |\n",
            "| 02 | [0 0 0 0] |\n",
            "| 03 | [0 0 1 0] |\n",
            "| 04 | [0 0 0 1] |\n",
            "| 05 | [0 0 0 0] |\n",
            "| 06 | [0 0 0 0] |\n",
            "| 07 | [0 0 0 0] |\n",
            "| 08 | [0 0 1 0] |\n",
            "| 09 | [0 0 0 1] |\n",
            "| 10 | [0 0 0 0] |\n",
            "| 11 | [0 0 0 0] |\n",
            "| 12 | [0 0 0 0] |\n",
            "| 13 | [0 0 0 0] |\n",
            "| 14 | [0 0 0 0] |\n",
            "| 15 | [0 0 1 0] |\n",
            "+----+-----------+\n",
            "AvgA under optimal control policy: 2.1506\n",
            "AvgA under no control policy: 0.46855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob = np.cumsum(t_m[0][0])\n",
        "for i in range(16):\n",
        "  print('idx: ' + str(i) + ' ' + str(np.round(t_m[0][0][i], 10)))\n",
        "  i += 1\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "for i in range(16):\n",
        "  print(np.round(prob[i], 10))\n",
        "  i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEVyi2st4kVa",
        "outputId": "a68bcafd-1727-44fb-8f64-07b6d958e718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx: 0 0.81450625\n",
            "idx: 1 0.04286875\n",
            "idx: 2 0.04286875\n",
            "idx: 3 0.00225625\n",
            "idx: 4 0.04286875\n",
            "idx: 5 0.00225625\n",
            "idx: 6 0.00225625\n",
            "idx: 7 0.00011875\n",
            "idx: 8 0.04286875\n",
            "idx: 9 0.00225625\n",
            "idx: 10 0.00225625\n",
            "idx: 11 0.00011875\n",
            "idx: 12 0.00225625\n",
            "idx: 13 0.00011875\n",
            "idx: 14 0.00011875\n",
            "idx: 15 6.25e-06\n",
            "\n",
            "\n",
            "0.81450625\n",
            "0.857375\n",
            "0.90024375\n",
            "0.9025\n",
            "0.94536875\n",
            "0.947625\n",
            "0.94988125\n",
            "0.95\n",
            "0.99286875\n",
            "0.995125\n",
            "0.99738125\n",
            "0.9975\n",
            "0.99975625\n",
            "0.999875\n",
            "0.99999375\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PROBLEM 2 - b (MATRIX FORM - VALUE ITERATION)\n",
        "\n",
        "b.1 𝑝=0.2, 𝜃=0.01, 𝛾=0.95"
      ],
      "metadata": {
        "id": "Te7BILAO2UBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.2\n",
        "g = 0.95\n",
        "t = 0.01\n",
        "\n",
        "t_m = generate_transition_matrix(p, s, a, conn_matrix)\n",
        "\n",
        "r_m = generate_reward_matrix(s, a)\n",
        "\n",
        "r_a = generate_reward_action(t_m, r_m, a)\n",
        "\n",
        "pi, vi = value_iteration_matrix(a, t_m, r_a, g, t)\n",
        "\n",
        "print(\"Optimal Policy:\")\n",
        "print(pi)\n",
        "#print(\"V star:\")\n",
        "#print(vi)\n",
        "\n",
        "av = performance_evaluation(pi, t_m)\n",
        "\n",
        "print(\"AvgA under optimal control policy: {}\".format(av))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiYyQxePZb5d",
        "outputId": "8559811e-e443-4ac5-d29b-73451e481092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy:\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "+----+-----------+\n",
            "| #i |   State   |\n",
            "+----+-----------+\n",
            "| 01 | [0 0 0 0] |\n",
            "| 02 | [0 1 0 0] |\n",
            "| 03 | [0 0 1 1] |\n",
            "| 04 | [1 0 0 1] |\n",
            "| 05 | [1 1 0 0] |\n",
            "| 06 | [1 1 1 0] |\n",
            "| 07 | [1 1 1 1] |\n",
            "| 08 | [0 0 1 1] |\n",
            "| 09 | [1 0 0 1] |\n",
            "| 10 | [0 0 0 0] |\n",
            "| 11 | [1 0 0 0] |\n",
            "| 12 | [0 0 0 0] |\n",
            "| 13 | [1 0 0 0] |\n",
            "| 14 | [1 1 0 0] |\n",
            "| 15 | [1 1 1 0] |\n",
            "+----+-----------+\n",
            "AvgA under optimal control policy: 1.98125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(16):\n",
        "  print('idx: ' + str(i) + ' ' + str(np.round(t_m[0][0][i], 10)))\n",
        "  i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvV3cOkXjgcB",
        "outputId": "48294526-e0d2-4b95-8f79-4faf3ce6dc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx: 0 0.4096\n",
            "idx: 1 0.1024\n",
            "idx: 2 0.1024\n",
            "idx: 3 0.0256\n",
            "idx: 4 0.1024\n",
            "idx: 5 0.0256\n",
            "idx: 6 0.0256\n",
            "idx: 7 0.0064\n",
            "idx: 8 0.1024\n",
            "idx: 9 0.0256\n",
            "idx: 10 0.0256\n",
            "idx: 11 0.0064\n",
            "idx: 12 0.0256\n",
            "idx: 13 0.0064\n",
            "idx: 14 0.0064\n",
            "idx: 15 0.0016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b.2 𝑝=0.45, 𝜃=0.01, 𝛾=0.95"
      ],
      "metadata": {
        "id": "1BI8uZsr2n1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.45\n",
        "g = 0.95\n",
        "t = 0.01\n",
        "\n",
        "t_m = generate_transition_matrix(p, s, a, conn_matrix)\n",
        "\n",
        "r_m = generate_reward_matrix(s, a)\n",
        "\n",
        "r_a = generate_reward_action(t_m, r_m, a)\n",
        "\n",
        "pi, vi = value_iteration_matrix(a, t_m, r_a, g, t)\n",
        "\n",
        "print(\"Optimal Policy:\")\n",
        "print(pi)\n",
        "#print(\"V star:\")\n",
        "#print(vi)\n",
        "\n",
        "av = performance_evaluation(pi, t_m)\n",
        "\n",
        "print(\"AvgA under optimal control policy: {}\".format(av))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ709o9vZu1k",
        "outputId": "23d03f25-25f3-4cda-b4b1-4bf127c1ab19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "+----+-----------+\n",
            "| #i |   State   |\n",
            "+----+-----------+\n",
            "| 01 | [0 1 1 0] |\n",
            "| 02 | [1 0 1 0] |\n",
            "| 03 | [1 0 1 0] |\n",
            "| 04 | [1 0 0 1] |\n",
            "| 05 | [0 1 1 0] |\n",
            "| 06 | [1 1 0 0] |\n",
            "| 07 | [0 0 1 1] |\n",
            "| 08 | [0 0 0 0] |\n",
            "| 09 | [0 0 0 1] |\n",
            "| 10 | [0 0 0 1] |\n",
            "| 11 | [0 1 0 1] |\n",
            "| 12 | [1 0 1 0] |\n",
            "| 13 | [1 1 1 1] |\n",
            "| 14 | [1 0 1 1] |\n",
            "| 15 | [1 0 1 0] |\n",
            "+----+-----------+\n",
            "AvgA under optimal control policy: 1.9112499999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(16):\n",
        "  print('idx: ' + str(i) + ' ' + str(np.round(t_m[0][0][i], 10)))\n",
        "  i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1jQZ7XzkjjN",
        "outputId": "5c96441d-a6a7-4ddc-c865-4bbcc6d7e30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx: 0 0.09150625\n",
            "idx: 1 0.07486875\n",
            "idx: 2 0.07486875\n",
            "idx: 3 0.06125625\n",
            "idx: 4 0.07486875\n",
            "idx: 5 0.06125625\n",
            "idx: 6 0.06125625\n",
            "idx: 7 0.05011875\n",
            "idx: 8 0.07486875\n",
            "idx: 9 0.06125625\n",
            "idx: 10 0.06125625\n",
            "idx: 11 0.05011875\n",
            "idx: 12 0.06125625\n",
            "idx: 13 0.05011875\n",
            "idx: 14 0.05011875\n",
            "idx: 15 0.04100625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PROBLEM 2 - c (MATRIX FORM - VALUE ITERATION)\n",
        "\n",
        "𝑝=0.05, 𝜃=0.01, 𝛾=0.95, all-zero initial state values\n",
        "\n",
        "a1 = [0, 0, 0, 0], a2 = [1, 0, 0, 0], a3 = [0, 1, 0, 0], a4 = [0, 0, 1, 0], a5 = [0, 0, 0, 1]"
      ],
      "metadata": {
        "id": "mGOmxS0y3zi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# action\n",
        "a_c = np.array([[0, 0, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
        "\n",
        "p = 0.05\n",
        "g = 0.95\n",
        "t = 0.01\n",
        "\n",
        "t_m_c = generate_transition_matrix(p, s, a_c, conn_matrix)\n",
        "\n",
        "r_m_c = generate_reward_matrix(s, a_c)\n",
        "\n",
        "r_a_c = generate_reward_action(t_m_c, r_m_c, a_c)\n",
        "\n",
        "pi_c, vi_c = value_iteration_matrix(a_c, t_m_c, r_a_c, g, t)\n",
        "\n",
        "print(\"Optimal Policy:\")\n",
        "print(pi_c)\n",
        "#print(\"V star:\")\n",
        "#print(vi)\n",
        "\n",
        "av_c = performance_evaluation(pi_c, t_m_c)\n",
        "\n",
        "av_noc_c = performance_evaluation(pi_c, t_m_c, True) # no control\n",
        "\n",
        "print(\"AvgA under optimal control policy: {}\".format(av_c))\n",
        "\n",
        "print(\"AvgA under no control policy: {}\".format(av_noc_c))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO9C5QAe4ZtY",
        "outputId": "26341ced-b30b-4e63-e09c-7e2530cee82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy:\n",
            "[2 2 2 2 2 2 2 2 3 2 2 2 4 2 2 2]\n",
            "+----+-----------+\n",
            "| #i |   State   |\n",
            "+----+-----------+\n",
            "| 01 | [0 1 0 1] |\n",
            "| 02 | [0 1 1 1] |\n",
            "| 03 | [0 1 1 1] |\n",
            "| 04 | [0 1 1 1] |\n",
            "| 05 | [0 1 1 1] |\n",
            "| 06 | [0 1 1 1] |\n",
            "| 07 | [0 1 1 1] |\n",
            "| 08 | [0 1 1 1] |\n",
            "| 09 | [0 1 1 1] |\n",
            "| 10 | [0 1 1 1] |\n",
            "| 11 | [0 1 1 1] |\n",
            "| 12 | [0 1 1 1] |\n",
            "| 13 | [0 1 1 1] |\n",
            "| 14 | [0 1 1 1] |\n",
            "| 15 | [0 1 1 0] |\n",
            "+----+-----------+\n",
            "+----+-----------+\n",
            "| #i |   State   |\n",
            "+----+-----------+\n",
            "| 01 | [0 0 0 0] |\n",
            "| 02 | [0 0 0 1] |\n",
            "| 03 | [0 1 1 0] |\n",
            "| 04 | [0 0 1 1] |\n",
            "| 05 | [0 0 0 1] |\n",
            "| 06 | [0 0 1 0] |\n",
            "| 07 | [0 0 0 1] |\n",
            "| 08 | [0 0 0 0] |\n",
            "| 09 | [0 0 0 0] |\n",
            "| 10 | [1 0 0 0] |\n",
            "| 11 | [1 1 0 0] |\n",
            "| 12 | [0 1 1 0] |\n",
            "| 13 | [0 0 1 1] |\n",
            "| 14 | [0 0 0 1] |\n",
            "| 15 | [0 0 0 0] |\n",
            "+----+-----------+\n",
            "AvgA under optimal control policy: 2.8404000000000003\n",
            "AvgA under no control policy: 0.49080000000000007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(16):\n",
        "  print('idx: ' + str(i) + ' ' + str(np.round(t_m_c[0][0][i], 10)))\n",
        "  i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsis-6ukvNHg",
        "outputId": "cc2853ba-65d3-4dc3-c3ba-8c08c4d6faf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx: 0 0.81450625\n",
            "idx: 1 0.04286875\n",
            "idx: 2 0.04286875\n",
            "idx: 3 0.00225625\n",
            "idx: 4 0.04286875\n",
            "idx: 5 0.00225625\n",
            "idx: 6 0.00225625\n",
            "idx: 7 0.00011875\n",
            "idx: 8 0.04286875\n",
            "idx: 9 0.00225625\n",
            "idx: 10 0.00225625\n",
            "idx: 11 0.00011875\n",
            "idx: 12 0.00225625\n",
            "idx: 13 0.00011875\n",
            "idx: 14 0.00011875\n",
            "idx: 15 6.25e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PROBLEM 2 - d (MATRIX FORM - POLICY ITERATION)\n",
        "\n",
        "𝑝=0.05, 𝜃=0.01, 𝛾=0.95, all-zero initial state values"
      ],
      "metadata": {
        "id": "Y4Pqvc71EngN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_matrix_pi(policy, t_mat):\n",
        "  m_pi = []\n",
        "  i = 0\n",
        "  for pol in policy:\n",
        "    m_pi.append(t_mat[pol][i])\n",
        "    i += 1\n",
        "\n",
        "  return np.array(m_pi)"
      ],
      "metadata": {
        "id": "ZXnvU2nXErEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_reward_pi(policy, r_sa):\n",
        "  r_pi = []\n",
        "  i = 0\n",
        "  for pol in policy:\n",
        "    r_pi.append(r_sa[pol][i])\n",
        "    i += 1\n",
        "\n",
        "  return np.array(r_pi)\n"
      ],
      "metadata": {
        "id": "JFvVaELNGNlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_v_pi(m_pi, r_pi, g):\n",
        "\n",
        "  i_mat = np.identity(max)\n",
        "\n",
        "  v_pi = np.dot(np.linalg.inv(np.subtract(i_mat, g*m_pi)), r_pi)\n",
        "\n",
        "  return v_pi"
      ],
      "metadata": {
        "id": "Z_rx5VvgGUf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_iteration_matrix(t_mat, rsa, g):\n",
        "  n = 0\n",
        "  pi = []\n",
        "  pi.append(np.zeros(max, dtype=np.int32))\n",
        "  p_star = 0\n",
        "\n",
        "  while (True):\n",
        "    #print(n)\n",
        "    #print(pi[n])\n",
        "    m_pi = generate_matrix_pi(pi[n], t_mat)\n",
        "    r_pi = generate_reward_pi(pi[n], rsa)\n",
        "    v_pi = calculate_v_pi(m_pi, r_pi, g)\n",
        "    \n",
        "    tmp_pi = []\n",
        "    for i in range(0, len(a)):\n",
        "      tmp_pi.append(rsa[i]+(g*np.dot(t_mat[i], v_pi)))\n",
        "    \n",
        "    #print(np.argmax(tmp_pi, axis=0))\n",
        "    pi.append(np.argmax(tmp_pi, axis=0))\n",
        "\n",
        "    if (np.array_equal(pi[n+1], pi[n])):\n",
        "      p_star = pi[n+1]\n",
        "      break\n",
        "    else:\n",
        "      n += 1\n",
        "\n",
        "  return p_star"
      ],
      "metadata": {
        "id": "Mo4s_40spU8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.05\n",
        "g = 0.95\n",
        "t = 0.01\n",
        "\n",
        "t_m = generate_transition_matrix(p, s, a, conn_matrix)\n",
        "\n",
        "r_m = generate_reward_matrix(s, a)\n",
        "\n",
        "r_a = generate_reward_action(t_m, r_m, a)\n",
        "\n",
        "pi = policy_iteration_matrix(t_m, r_a, g)\n",
        "\n",
        "print(\"Optimal Policy:\")\n",
        "print(pi)\n",
        "#print(\"V star:\")\n",
        "#print(vi)\n",
        "\n",
        "av = performance_evaluation(pi, t_m)\n",
        "\n",
        "av_noc = performance_evaluation(pi, t_m, True) # no control\n",
        "\n",
        "print(\"AvgA under optimal control policy: {}\".format(av))\n",
        "\n",
        "print(\"AvgA under no control policy: {}\".format(av_noc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1qu96NKMCAg",
        "outputId": "a5f28f15-5233-448c-c8d0-39ce8f4ecc34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy:\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "+----+-----------+\n",
            "| #i |   State   |\n",
            "+----+-----------+\n",
            "| 01 | [1 0 1 1] |\n",
            "| 02 | [1 0 0 0] |\n",
            "| 03 | [1 1 0 0] |\n",
            "| 04 | [1 1 1 0] |\n",
            "| 05 | [1 0 1 0] |\n",
            "| 06 | [1 0 0 0] |\n",
            "| 07 | [1 1 0 0] |\n",
            "| 08 | [1 1 1 0] |\n",
            "| 09 | [1 0 1 1] |\n",
            "| 10 | [1 0 0 0] |\n",
            "| 11 | [1 1 0 0] |\n",
            "| 12 | [1 1 1 0] |\n",
            "| 13 | [1 0 1 1] |\n",
            "| 14 | [1 0 0 0] |\n",
            "| 15 | [1 1 0 0] |\n",
            "+----+-----------+\n",
            "+----+-----------+\n",
            "| #i |   State   |\n",
            "+----+-----------+\n",
            "| 01 | [0 0 1 1] |\n",
            "| 02 | [0 0 0 1] |\n",
            "| 03 | [0 0 0 0] |\n",
            "| 04 | [0 0 0 0] |\n",
            "| 05 | [0 0 1 0] |\n",
            "| 06 | [0 0 0 1] |\n",
            "| 07 | [0 0 0 0] |\n",
            "| 08 | [0 0 0 1] |\n",
            "| 09 | [0 0 0 0] |\n",
            "| 10 | [0 0 0 1] |\n",
            "| 11 | [0 0 0 0] |\n",
            "| 12 | [0 0 0 1] |\n",
            "| 13 | [1 0 0 0] |\n",
            "| 14 | [0 1 0 0] |\n",
            "| 15 | [1 0 0 1] |\n",
            "+----+-----------+\n",
            "AvgA under optimal control policy: 2.15675\n",
            "AvgA under no control policy: 0.47875\n"
          ]
        }
      ]
    }
  ]
}
